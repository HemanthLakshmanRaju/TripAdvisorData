county text,
year integer,
percent_four_plus_years_college numeric,
percent_has_some_college numeric,
percent_hs_diploma numeric,
`percent_less than_hs_diploma` numeric,
PRIMARY KEY(fips,year),
FOREIGN KEY(fips) REFERENCES fips(fips))
without rowid")
dbWriteTable(conn = db, name = "education_data", value = education_data, row.names=FALSE, append = TRUE)
dbSendQuery(conn=db,"CREATE TABLE unemp_data(
fips integer,
year integer,
percent_unemployed numeric,
PRIMARY KEY(fips,year),
FOREIGN KEY(fips,year) REFERENCES education_data(fips,year))
without rowid")
dbWriteTable(conn = db, name = "unemp_data", value = unemp_data, row.names=FALSE, append = TRUE)
library(RSQLite)
library(tidyverse)
library(ggplot2)
db<-dbConnect(SQLite(),dbname="Test.sqlite")
setwd("C:/Users/Hemanth Lakshman/Documents/CSR/Assignment 10")
ed_data<-read.csv("FipsEducationsDA5020v2.csv",sep=",")
unemp_data<-read.csv("FipsUnemploymentDA5020(1).csv",sep=",")
ed_data$county_state<-gsub("[cC]ounty$","",ed_data$county_state)
ed_data<-ed_data%>%
separate(county_state,into=c("state","county"))
ed_data<-ed_data%>%
spread(percent_measure,percent)
fips<-ed_data%>%
select(fips,state,county,rural_urban_cont_code)%>%
distinct()
education_data<-ed_data%>%
select(fips,state,county,year,percent_four_plus_years_college,percent_has_some_college,
percent_hs_diploma,
`percent_less than_hs_diploma`)
rural_urban_code<-ed_data%>%
select(rural_urban_cont_code,description)%>%
distinct()
dbSendQuery(conn=db,"CREATE TABLE rural_urban_code(
rural_urban_cont_code TEXT PRIMARY KEY,
description TEXT)
WITHOUT ROWID")
View(rural_urban_code)
dbGetQuery(db, "SELECT county,state,year,`percent_less than_hs_diploma`
from education_data
WHERE year='1970'and county='Nantucket' and state='MA'")
dbGetQuery(db, "SELECT county,state,year,`percent_less than_hs_diploma`
from education_data
WHERE year='2015'and county='Nantucket' and state='MA'")
dbGetQuery(db,"select AVG(`percent_less than_hs_diploma`) as Average
from education_data
where state='AL'and year='2015'and `percent_less than_hs_diploma` is not null")
dbGetQuery(db,"select AVG(percent_four_plus_years_college) as Average
from education_data
where state='MA'and year='2015'and percent_four_plus_years_college is not null")
dbGetQuery(db,"select AVG(`percent_less than_hs_diploma`) as Average,year
from education_data
where state='AL'
group by year")
dbGetQuery(db,"select count(f.rural_urban_cont_code) as total,f.rural_urban_cont_code
from fips f
join  rural_urban_code r
on f.rural_urban_cont_code=r.rural_urban_cont_code
group by f.rural_urban_cont_code
order by count(f.rural_urban_cont_code) desc
limit 1")
dbGetQuery(db,"select county,state
from fips f
join  rural_urban_code r
on f.rural_urban_cont_code=r.rural_urban_cont_code
where f.rural_urban_cont_code='NULL'")
dbGetQuery(db,"select min(percent_four_plus_years_college) as Lowest
from education_data
where state='MS'and year='2010'")
dbGetQuery(db,"select count(state)
from fips
where rural_urban_cont_code='NULL'
group by state")
dbGetQuery(db,"select county,state
from education_data e
left join  unemp_data u
on e.fips=u.fips and e.year=u.year
where e.year=2015 and percent_four_plus_years_college< percent_unemployed")
dbGetQuery(db,"select county,state,percent_four_plus_years_college
from education_data e
order by percent_four_plus_years_college desc
limit 1")
get_state_county_education_data_dplyr<-function(edf,State){
c<-edf%>%
filter(state==State)
aa<-ggplot(data=c,aes(year,percent_four_plus_years_college))+geom_smooth(aes(colour=county),se=F,method=loess)
bb<-ggplot(data=c,aes(year,percent_has_some_college))+geom_smooth(aes(colour=county),se=F,method=loess)
cc<-ggplot(data=c,aes(year,percent_hs_diploma))+geom_smooth(aes(colour=county),se=F,method=loess)
dd<-ggplot(data=c,aes(year,`percent_less than_hs_diploma`))+geom_smooth(aes(colour=county),se=F,method=loess)
suppressWarnings(print(ggarrange(aa,bb,cc,dd)))
}
get_state_county_education_data_dplyr(education_data,"MA")
install.packages("ggpubr")
knitr::opts_chunk$set(
# mute messages output
message = FALSE
)
setwd("C:/Users/Hemanth Lakshman/Documents/CSR/Assignment 12/MongoHwk")
library(mongolite)
authors<-read.csv("authors.csv")
books<-read.csv("Books.csv")
publishers<-read.csv("Publishers.csv")
users<-read.csv("Users.csv")
AUTHORS<-mongo("authors")
setwd("C:/Users/Hemanth Lakshman/Documents/CSR/Assignment 12/MongoHwk")
library(mongolite)
authors<-read.csv("authors.csv")
books<-read.csv("Books.csv")
publishers<-read.csv("Publishers.csv")
users<-read.csv("Users.csv")
AUTHORS<-mongo("authors")
AUTHORS$insert(authors)
BOOKS<-mongo("books")
BOOKS$insert(books)
PUBLISHERS<-mongo("publishers")
PUBLISHERS$insert(publishers)
USERS<-mongo("users")
USERS$insert(users)
BOOKS$count()
BOOKS$find()
BOOKS$find('{"author":"Danielle Steel"}')
USERS$find('[{"dateOfCreation" : {"$gt":"12/15/2014"}},{"city":"Boston"}]')
USERS$find('[{"dateOfCreation" : {"$gt":"12/15/2014"}}
,{"city":"Boston"}
]')
USERS$find('[{"dateOfCreation" : {$gt:"12/15/2014"}}
,{"city":"Boston"}
]')
USERS$find({"dateOfCreation" : {$gt:"12/15/2014"}}
USERS$find('[{"dateOfCreation" : {$gt:"12/15/2014"}}
,{"city":"Boston"}
]')
USERS$find('[{"dateOfCreation" : {"$gt":"12/15/2014"}}
,{"city":"Boston"}
]')
BOOKS$find('{"publisher_1":{"$ne":null}}')
BOOKS$find('{"publisher_1":{$ne:null}}')
BOOKS$find('{"notebody":{"$ne":null}}')
PUBLISHERS$find(sort='{"date":1}',limit = 1)
USERS$aggregate('[{"$group":
{"_id": "$state",
"num_users": {"$sum":1}
}
}]')
USERS$aggregate('[{"$group":
{"_id": "dateOfCreation",
"count":{"$sum":1}
}
},
{"$sort":{"_id":-1}}
]')
library(dplyr)
a<-USERS$aggregate('[{"$group":
{"_id": "$zip",
"num_users": {"$sum":1}
}
}]')
c<-arrange(a,desc(num_users))
head(c,1)
USERS$find('[{"dateOfCreation" : {"$gte":"12/15/2014"}}
,{"city":"Boston"}
]')
USERS$find('{"dateOfCreation" : {"$gt":"12/15/2014"}}
,{"city":"Boston"}
')
data <- USERS$find('{"dateOfCreation" : {"$gt" : "12/15/2014"}}
,{"city":"Boston"}
')
data <- USERS$find('{"dateOfCreation" : {"$gt" : "12/15/2014"}
,{"city":"Boston"}}
')
data <- USERS$find('[{"dateOfCreation" : {"$gt" : "12/15/2014"}
,{"city":"Boston"}}
]')
USERS$find('[{"dateOfCreation" : {$gt:"12/15/2014"}}
,{"city":"Boston"}
]')
USERS$find('[{"dateOfCreation" : {"$gt":"12/15/2014"}}
,{"city":"Boston"}
]')
USERS$find('{"dateOfCreation" : {"$gt" : "12/15/2014"}}
,{"city":"Boston"}
')
USERS$find('{"dateOfCreation" : {"$gt" : "12/15/2014"}}
')
USERS$find(
'{"dateOfCreation" : {"$gte" : {"$date" : "12/15/2014"}}}
')
USERS$find('{"dateOfCreation" : {"$gt":"12/15/2014"}},{"city" : "Boston"}')
data <- USERS$find('{"dateOfCreation" : {"$gte":"12/15/2014"}},{"city" : "Boston"}')
data <- USERS$find('[{"dateOfCreation" : {"$gte":"12/15/2014"}},{"city" : "Boston"}]')
data <- USERS$find('[{"dateOfCreation" : {"$gte":"12/15/2014"}}
,{"city" : "Boston"}
]')
data <- USERS$find('[{"dateOfCreation" : {"$gte":"12/15/2014"}}
,{"city" : "Boston"}
]')
data
USERS$find(
query = '{"dateOfCreation" : {"$gte":"12/15/2014"}}
,{"city" : "Boston"}
')
USERS$find(
query = '{"dateOfCreation" : {"$gt":"12/15/2014"}}
,{"city" : "Boston"}
')
USERS$find(
query = '{"dateOfCreation" : {"$gt":12/15/2014}}
,{"city" : "Boston"}
')
BOOKS$find('{"publisher_1":{"$ne":null}}')
BOOKS$count('{}')
BOOKS$find('{}')
USERS$find('{"city" : "Boston"}')
BOOKS$find('{
"publisher_1": {
"$ne": null
}
}');
BOOKS$find('{
"publisher_1": {
"$ne": null
}
}')
PUBLISHERS$find('{sort='{"date":1}',limit = 1}')
USERS$find('{"city" : "Boston"}',{"dateOfCreation" : {$regex : ".*2014.*"}})
USERS$find('{"city" : "Boston"},{"dateOfCreation" : {$regex : ".*2014.*"}}')
USERS$find('{"dateOfCreation" : {$regex : ".*2014.*"}}')
USERS$find('{"dateOfCreation" : {$regex : "2014"}}')
USERS$find('{"dateOfCreation": /.*2014.*/}')
USERS$find('{"dateOfCreation" : /2014/}')
USERS$find('{"dateOfCreation" : {"$regex"" : "2015"}}')
USERS$find('{"dateOfCreation" : {"$regex" : "2015"}}')
USERS$find('{"dateOfCreation" : {"$regex" : "2015"}}, {"city":"Boston"}')
USERS$find('{"dateOfCreation" : {"$regex" : "2015"}}')
USERS$find('{"city":"Boston"},{"dateOfCreation" : {"$regex" : "2015"}}')
USERS$find('{"city":"Boston"}
,{"dateOfCreation" : {"$regex" : "2015"}}
')
USERS$find('{"dateOfCreation" : {"$regex" : "2015"}}
')
USERS$find('{"city" : "Boston"}
')
USERS$find('{"dateOfCreation" : {"$regex" : "2015"}}, {"city" : "Boston"}
')
USERS$find('{"dateOfCreation" : {"$regex" : "2015"}}
,{"city" : "Boston"}
')
USERS$find('{"dateOfCreation" : {"$regex" : "2015"}}
& {"city" : "Boston"}
')
USERS$find('{"dateOfCreation" : {"$regex" : "2015"}}
')
PUBLISHERS$find('{sort='{"date":1}',limit = 1}')
PUBLISHERS$find('{sort='{"date":1}',limit = 1}')
PUBLISHERS$find(sort='{"date":1}',limit = 1)
USERS$aggregate('{"$group":
{"_id": "$state",
"num_users": {"$sum":1}
}
}')
BOOKS$find('{"publisher" : 1}
,{"publisher_1" : 1
')
BOOKS$find('{"publisher" : 1}
')
BOOKS$find('{"publisher" : TRUE}
')
BOOKS$find('{"publisher"}
')
BOOKS$find('{"notebody":{
"$ne":null
}
}')
BOOKS$find('{}')
BOOKS$find('{"publisher_1":{"$ne":null}}')
library(dplyr)
a<-USERS$aggregate('[{"$group":{"_id": "$zip","num_users": {"$sum":1}}}]')
c<-arrange(a,desc(num_users))
c
The CAP Theorem states that it is impossible for a distributed data store to simultaneously provide more than two out of the follo
library(dplyr)
a<-USERS$aggregate('[{"$group":{"_id": "$zip","num_users": {"$sum":1}}}]')
c<-arrange(a,desc(num_users))
head(c,1)
library(dplyr)
agg<-USERS$aggregate('[{"$group":{"_id": "$zip","most_no_of_users": {"$sum":1}}}]')
usr_cnt<-arrange(agg,desc(most_no_of_users))
head(usr_cnt,1)
library(dplyr)
agg<-USERS$aggregate('[{"$group":{"_id": "$zip","no_of_users": {"$sum":1}}}]')
usr_cnt<-arrange(agg,desc(no_of_users))
head(usr_cnt,1)
library(dplyr)
agg<-USERS$aggregate('[{"$group":{"_id": "$zip","no_of_users": {"$sum":1}}}]')
usr_cnt<-arrange(agg,desc(no_of_users))
head(usr_cnt,1)
USERS$aggregate('[{"$group":{"_id": "dateOfCreation","count":{"$sum":1}}},{"$sort":{"_id":-1}}]')
USERS$aggregate('{"$group":{"_id": "dateOfCreation","count":{"$sum":1}}},{"$sort":{"_id":-1}}')
USERS$aggregate('[{"$group":{"_id": "dateOfCreation","count":{"$sum":1}}},{"$sort":{"_id":-1}}]')
USERS$aggregate('{"$group":{"_id": "$state","no_of_users": {"$sum":1}}}')
USERS$aggregate('[{"$group":
{"_id": "$state",
"num_users": {"$sum":1}
}
}]')
USERS$aggregate('[{"$group":
{"_id": "$state",
"no_of_users": {"$sum":1}
}
}]')
agg<-USERS$aggregate('[{"$group":{"_id": "$state","no_of_users": {"$sum":1}}}]')
usr_cnt<-arrange(agg,desc(no_of_users))
head(usr_cnt,1)
USERS$aggregate('[{"$group":{"_id": "dateOfCreation : {"$regex" : "2015"}","count":{"$sum":1}}},{"$sort":{"_id":-1}}]')
USERS$aggregate('[{"$group":{"_id": "dateOfCreation","count":{"$sum":1}}},{"$sort":{"_id":-1}}]')
usr_2015 <- USERS$find('{"dateOfCreation" : {"$regex" : "2015"}}
')
no_of_users<-sr_2015$aggregate('[{"no_of_users": {"$sum":1}}]')
usr_2015 <- USERS$find('{"dateOfCreation" : {"$regex" : "2015"}}
')
no_of_users<-usr_2015$aggregate('[{"no_of_users": {"$sum":1}}]')
usr_2015 <- USERS$find('{"dateOfCreation" : {"$regex" : "2015"}}
')
no_of_users<-count(usr_2015)
no_of_users
agg<-USERS$aggregate('[{"$group":{"_id": "$zip","no_of_users": {"$sum":1}}}]')
usr_cnt<-arrange(agg,desc(no_of_users))
head(usr_cnt,1)
PUBLISHERS$find(sort='{"date":1}',limit = 1)
BOOKS$find('{"notebody":{"$ne":null}}')
BOOKS$find('{"publisher_1":{"$ne":null}}')
knitr::opts_chunk$set(
# mute messages output
message = FALSE
)
USERS$find('{"dateOfCreation":{"$gte":"12/15/2014"},"city":"Boston"}')
library(rvest)
library(rvest)
library(dplyr)
library(tidyverse)
library(stringr)
library(tibble)
library(RSQLite)
restaurant<-read.csv("Restaurants.csv",header=T, na.strings=c("","NA"))
hotel<-read.csv("Hotels.csv")
flights<-read.csv("Flights.csv")
Points_of_interest<-read.csv("Points_of_interest.csv")
str(restaurant)
restaurant$Review_1 <- as.character(restaurant$Review_1)
restaurant$Review_2 <- as.character(restaurant$Review_2)
restaurant$Review_Count<-gsub("[A-z]","",restaurant$Review_Count)
restaurant<- unite(restaurant,"Review",c(Review_1,Review_2),sep=",",remove= TRUE)
restaurant <- unite(restaurant,"Cusine",c(Cuisines_offered_1,Cusines_offered_2,Cuisines_offered_3,Cusines_offered_4,Cuisines_offered_5),sep=",",remove=TRUE)
restaurant$Cusine <- gsub("[NA]","",restaurant$Cusine)
library(rvest)
library(dplyr)
library(tidyverse)
library(stringr)
library(tibble)
library(RSQLite)
restaurant<-read.csv("Restaurants.csv",header=T, na.strings=c("","NA"))
setwd("C:/Users/Hemanth Lakshman/Documents/Trip Advisor Project")
restaurant<-read.csv("Restaurants.csv",header=T, na.strings=c("","NA"))
hotel<-read.csv("Hotels.csv")
flights<-read.csv("Flights.csv")
Points_of_interest<-read.csv("Points_of_interest.csv")
str(restaurant)
restaurant$Review_1 <- as.character(restaurant$Review_1)
restaurant$Review_2 <- as.character(restaurant$Review_2)
restaurant$Review_Count<-gsub("[A-z]","",restaurant$Review_Count)
restaurant<- unite(restaurant,"Review",c(Review_1,Review_2),sep=",",remove= TRUE)
restaurant <- unite(restaurant,"Cusine",c(Cuisines_offered_1,Cusines_offered_2,Cuisines_offered_3,Cusines_offered_4,Cuisines_offered_5),sep=",",remove=TRUE)
restaurant$Cusine <- gsub("[NA]","",restaurant$Cusine)
restaurant
restaurant
hotel$address <- rep(NA,nrow(hotel))
hotel$address <- rep(NA,nrow(hotel))
for(i in seq_along(nrow(hotel))){
htm <- read_html(hotel$Hotel_Web_Link[[i]])
add <- html_node(css="span.street-address") %>% html_text()
print(add)
hotel$address[[i]] <- add
}
hotel <- as.data.frame(hotel,stringsAsFactors=F)
for(i in seq_along(nrow(hotel))){
htm <- read_html(hotel$Hotel_Web_Link[[i]])
add <- html_node(css="span.street-address") %>% html_text()
print(add)
hotel$address[[i]] <- add
}
library(rvest)
for(i in seq_along(nrow(hotel))){
htm <- read_html(hotel$Hotel_Web_Link[[i]])
add <- html_node(css="span.street-address") %>% html_text()
print(add)
hotel$address[[i]] <- add
}
library(rvest)
for(i in seq_along(nrow(hotel))){
htm <- read_html(hotel$Hotel_Web_Link[[i]])
add <- html_node(css="span.street-address") %>% html_text()
print(add)
hotel$address[[i]] <- add
}
hotel$address <- rep(NA,nrow(hotel))
for(i in seq_along(nrow(hotel))){
print(hotel$Hotel_Web_Link[[i]])
htm <- read_html(hotel$Hotel_Web_Link[[i]])
add <- html_node(css="span.street-address") %>% html_text()
print(add)
hotel$address[[i]] <- add
}
hotel <- as.data.frame(hotel,stringsAsFactors=F)
for(i in seq_along(nrow(hotel))){
print(hotel$Hotel_Web_Link[[i]])
htm <- read_html(hotel$Hotel_Web_Link[[i]])
add <- html_node(css="span.street-address") %>% html_text()
print(add)
hotel$address[[i]] <- add
}
hotel$Hotel_Web_Link <- as.character(hotel$Hotel_Web_Link)
class(hotel$Hotel_Web_Link)
for(i in seq_along(nrow(hotel))){
print(hotel$Hotel_Web_Link[[i]])
htm <- read_html(hotel$Hotel_Web_Link[[i]])
add <- html_node(css="span.street-address") %>% html_text()
print(add)
hotel$address[[i]] <- add
}
for(i in seq_along(nrow(hotel))){
print(hotel$Hotel_Web_Link[[i]])
htm <- read_html(hotel$Hotel_Web_Link[[i]])
add <- html_node("css","span.street-address") %>% html_text()
print(add)
hotel$address[[i]] <- add
}
for(i in seq_along(nrow(hotel))){
print(hotel$Hotel_Web_Link[[i]])
htm <- read_html(hotel$Hotel_Web_Link[[i]])
add <- htm %>% html_node(css="span.street-address") %>% html_text()
print(add)
hotel$address[[i]] <- add
}
for(i in nrow(hotel)){
print(hotel$Hotel_Web_Link[[i]])
htm <- read_html(hotel$Hotel_Web_Link[[i]])
add <- htm %>% html_node(css="span.street-address") %>% html_text()
print(add)
hotel$address[[i]] <- add
}
nrow(hotel)
for(i in 1:nrow(hotel)){
print(hotel$Hotel_Web_Link[[i]])
htm <- read_html(hotel$Hotel_Web_Link[[i]])
add <- htm %>% html_node(css="span.street-address") %>% html_text()
print(add)
hotel$address[[i]] <- add
}
View(hotel)
for(i in 1:nrow(hotel)){
print(hotel$Hotel_Web_Link[[i]])
htm <- read_html(hotel$Hotel_Web_Link[[i]])
add1 <- htm %>% html_node(css="span.street-address") %>% html_text()
add2 <- htm %>% html_node(css="span.extended-address") %>% html_text()
add3 <- htm %>% html_node(css="span.locality") %>% html_text()
add4 <- htm %>% html_node(css="span.country-name") %>% html_text()
print(add)
hotel$address[[i]] <- unite(add1,add2,add3,add4,sep=',')
}
for(i in 1:nrow(hotel)){
print(hotel$Hotel_Web_Link[[i]])
htm <- read_html(hotel$Hotel_Web_Link[[i]])
add1 <- htm %>% html_node(css="span.street-address") %>% html_text()
add2 <- htm %>% html_node(css="span.extended-address") %>% html_text()
add3 <- htm %>% html_node(css="span.locality") %>% html_text()
add4 <- htm %>% html_node(css="span.country-name") %>% html_text()
print(add)
hotel$address[[i]] <- paste(add1,add2,add3,add4,collapse=',')
}
View(restaurant)
View(restaurant)
restaurant$Cusine <- gsub("[NA,]","",restaurant$Cusine)
restaurant$Cuisine <- gsub("[NA,]","",restaurant$Cusine)
View(restaurant)
View(restaurant)
View(restaurant)
View(restaurant)
View(restaurant)
View(restaurant)
restaurant$Cuisine <- gsub("[NA]\\,","",restaurant$Cuisine)
rm(restaurant
)
restaurant<-read.csv("Restaurants.csv",header=T, na.strings=c("","NA"))
View(restaurant)
restaurant <- unite(restaurant,"Cuisine",c(Cuisines_offered_1,Cusines_offered_2,Cuisines_offered_3,Cuisines_offered_4,Cuisines_offered_5),sep=",",remove=TRUE)
restaurant$Cuisine <- gsub("(?:NA\\,)","",restaurant$Cuisine)
View(restaurant)
names(restaurant)
names(restaurant) <- c("Restaurant_Name","Restaurant_Web_Link","Review_Count","Price.Range","Cuisines_offered_1","Cuisines_offered_2","Review_1","Review_1_date","Review_2","Review_2_date","Category","Cuisines_offered_3","Cuisines_offered_4","Cuisines_offered_5")
restaurant<- unite(restaurant,"Review",c(Review_1,Review_2),sep=",",remove= TRUE)
restaurant <- unite(restaurant,"Cuisine",c(Cuisines_offered_1,Cuisines_offered_2,Cuisines_offered_3,Cuisines_offered_4,Cuisines_offered_5),sep=",",remove=TRUE)
restaurant$Cuisine <- gsub("(?:NA\\,)","",restaurant$Cuisine)
restaurant$Cuisine <- gsub("(?:NA\\,)|NA","",restaurant$Cuisine)
restaurant$Cuisine <- gsub("\\,$","",restaurant$Cuisine)
